{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Complete the Machine Learning Prediction lab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPt1SgvcD2/EzDo2dIfTPkK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Najmusseher/IBM-Data-Science-Professional-Certificate-Course/blob/main/Complete_the_Machine_Learning_Prediction_lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Space X Falcon 9 First Stage Landing Prediction\n",
        "Assignment: Machine Learning Prediction\n",
        "Estimated time needed: 60 minutes\n",
        "\n",
        "Space X advertises Falcon 9 rocket launches on its website with a cost of 62 million dollars; other providers cost upward of 165 million dollars each, much of the savings is because Space X can reuse the first stage. Therefore if we can determine if the first stage will land, we can determine the cost of a launch. This information can be used if an alternate company wants to bid against space X for a rocket launch. In this lab, you will create a machine learning pipeline to predict if the first stage will land given the data from the preceding labs.\n",
        "\n",
        "\n",
        "\n",
        "Several examples of an unsuccessful landing are shown here:\n",
        "\n",
        "\n",
        "\n",
        "Most unsuccessful landings are planed. Space X; performs a controlled landing in the oceans.\n",
        "\n",
        "**Objectives**\n",
        "Perform exploratory Data Analysis and determine Training Labels\n",
        "\n",
        "create a column for the class\n",
        "Standardize the data\n",
        "Split into training data and test data\n",
        "-Find best Hyperparameter for SVM, Classification Trees and Logistic Regression\n",
        "\n",
        "Find the method performs best using test data"
      ],
      "metadata": {
        "id": "AZbdAQNE50T9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import Libraries and Define Auxiliary Functions\n",
        "We will import the following libraries for the lab"
      ],
      "metadata": {
        "id": "a7Hc1wWT58-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pandas is a software library written for the Python programming language for data manipulation and analysis.\n",
        "import pandas as pd\n",
        "# NumPy is a library for the Python programming language, adding support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays\n",
        "import numpy as np\n",
        "# Matplotlib is a plotting library for python and pyplot gives us a MatLab like plotting framework. We will use this in our plotter function to plot data.\n",
        "import matplotlib.pyplot as plt\n",
        "#Seaborn is a Python data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics\n",
        "import seaborn as sns\n",
        "# Preprocessing allows us to standarsize our data\n",
        "from sklearn import preprocessing\n",
        "# Allows us to split our data into training and testing data\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Allows us to test parameters of classification algorithms and find the best one\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "# Logistic Regression classification algorithm\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# Support Vector Machine classification algorithm\n",
        "from sklearn.svm import SVC\n",
        "# Decision Tree classification algorithm\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "# K Nearest Neighbors classification algorithm\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "metadata": {
        "id": "KOqsoKYz53nO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function is to plot the confusion matrix.\n"
      ],
      "metadata": {
        "id": "sSgX_drq6Bdr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(y,y_predict):\n",
        "    \"this function plots the confusion matrix\"\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "\n",
        "    cm = confusion_matrix(y, y_predict)\n",
        "    ax= plt.subplot()\n",
        "    sns.heatmap(cm, annot=True, ax = ax); #annot=True to annotate cells\n",
        "    ax.set_xlabel('Predicted labels')\n",
        "    ax.set_ylabel('True labels')\n",
        "    ax.set_title('Confusion Matrix'); \n",
        "    ax.xaxis.set_ticklabels(['did not land', 'land']); ax.yaxis.set_ticklabels(['did not land', 'landed'])"
      ],
      "metadata": {
        "id": "hqYIhhDV6GVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load the dataframe\n",
        "Load the data\n"
      ],
      "metadata": {
        "id": "bIQhcgxr6I_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data = pd.read_csv(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/datasets/dataset_part_2.csv\")\n",
        "\n",
        "# If you were unable to complete the previous lab correctly you can uncomment and load this csv\n",
        "\n",
        "# data = pd.read_csv('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DS0701EN-SkillsNetwork/api/dataset_part_2.csv')\n",
        "\n",
        "data.head()"
      ],
      "metadata": {
        "id": "2NVebBRi6Qie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = pd.read_csv('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/datasets/dataset_part_3.csv')\n",
        "\n",
        "# If you were unable to complete the previous lab correctly you can uncomment and load this csv\n",
        "\n",
        "# X = pd.read_csv('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DS0701EN-SkillsNetwork/api/dataset_part_3.csv')\n",
        "\n",
        "X.head(100)"
      ],
      "metadata": {
        "id": "-Diq_NV86Xsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TASK 1\n",
        "Create a NumPy array from the column Class in data, by applying the method to_numpy() then assign it to the variable Y,make sure the output is a Pandas series (only one bracket df['name of column'])."
      ],
      "metadata": {
        "id": "bPlyalXx6YjU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y = data['Class'].to_numpy()"
      ],
      "metadata": {
        "id": "tSJKO3cT6xDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TASK 2\n",
        "Standardize the data in X then reassign it to the variable X using the transform provided below."
      ],
      "metadata": {
        "id": "oDzm6hYr6zaZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# students get this \n",
        "transform = preprocessing.StandardScaler()\n",
        "X = transform.fit_transform(X)"
      ],
      "metadata": {
        "id": "gS_lqCf562Z6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We split the data into training and testing data using the function train_test_split. The training data is divided into validation data, a second set used for training data; then the models are trained and hyperparameters are selected using the function GridSearchCV.\n"
      ],
      "metadata": {
        "id": "F-_zu9lN69YS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TASK 3\n",
        "Use the function train_test_split to split the data X and Y into training and test data. Set the parameter test_size to 0.2 and random_state to 2. The training data and test data should be assigned to the following labels."
      ],
      "metadata": {
        "id": "A9FrDzdy7AXy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)"
      ],
      "metadata": {
        "id": "PTHKUWWl7F43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we can see we only have 18 test samples."
      ],
      "metadata": {
        "id": "KZaf8Fqd7I4D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y_test.shape"
      ],
      "metadata": {
        "id": "Vrf_1_sB7MrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TASK 4\n",
        "Create a logistic regression object then create a GridSearchCV object logreg_cv with cv = 10. Fit the object to find the best parameters from the dictionary parameters.\n"
      ],
      "metadata": {
        "id": "mLAvm0LY7NkV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parameters ={'C':[0.01,0.1,1],\n",
        "             'penalty':['l2'],\n",
        "             'solver':['lbfgs']}"
      ],
      "metadata": {
        "id": "8sNm9vaM7a_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameters ={\"C\":[0.01,0.1,1],'penalty':['l2'], 'solver':['lbfgs']}# l1 lasso l2 ridge\n",
        "lr=LogisticRegression()\n",
        "logreg_cv = GridSearchCV(lr, parameters, cv = 10)\n",
        "logreg_cv.fit(X_train, Y_train)"
      ],
      "metadata": {
        "id": "dUcOaOp77bqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We output the GridSearchCV object for logistic regression. We display the best parameters using the data attribute best_params\\_ and the accuracy on the validation data using the data attribute best_score\\_.\n"
      ],
      "metadata": {
        "id": "b1GL0pVN7kwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"tuned hpyerparameters :(best parameters) \",logreg_cv.best_params_)\n",
        "print(\"accuracy :\",logreg_cv.best_score_)"
      ],
      "metadata": {
        "id": "C-NK0W5J7yGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TASK 5\n",
        "Calculate the accuracy on the test data using the method score:"
      ],
      "metadata": {
        "id": "kagNB2ka745v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for comparing the accuracy by the methods\n",
        "methods = []\n",
        "accuracy = []\n",
        "\n",
        "methods.append('Logistic regression')\n",
        "accuracy.append(logreg_cv.score(X_test, Y_test))"
      ],
      "metadata": {
        "id": "om2jGP-G8AOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"test set accuracy :\",logreg_cv.score(X_test, Y_test))"
      ],
      "metadata": {
        "id": "3CjA9CG_8Diw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yhat=logreg_cv.predict(X_test)\n",
        "plot_confusion_matrix(Y_test,yhat)"
      ],
      "metadata": {
        "id": "ARb0B0YC8Ipd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Examining the confusion matrix, we see that logistic regression can distinguish between the different classes. We see that the major problem is false positives.\n",
        "\n",
        "#TASK 6\n",
        "Create a support vector machine object then create a GridSearchCV object svm_cv with cv - 10. Fit the object to find the best parameters from the dictionary parameters."
      ],
      "metadata": {
        "id": "K04nd23B8Pr-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = {'kernel':('linear', 'rbf','poly','rbf', 'sigmoid'),\n",
        "              'C': np.logspace(-3, 3, 5),\n",
        "              'gamma':np.logspace(-3, 3, 5)}\n",
        "svm = SVC()"
      ],
      "metadata": {
        "id": "6F8P59gd8Z7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm_cv = GridSearchCV(svm, parameters, cv = 10)\n",
        "svm_cv.fit(X_train, Y_train)"
      ],
      "metadata": {
        "id": "WcYCckpE8d_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"tuned hpyerparameters :(best parameters) \",svm_cv.best_params_)\n",
        "print(\"accuracy :\",svm_cv.best_score_)"
      ],
      "metadata": {
        "id": "FMzR5S958grT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TASK 7\n",
        "Calculate the accuracy on the test data using the method score:"
      ],
      "metadata": {
        "id": "MYMYJ-IP8oWZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "methods.append('Support vector machine')\n",
        "accuracy.append(svm_cv.score(X_test, Y_test))\n",
        "print(\"test set accuracy :\",svm_cv.score(X_test, Y_test))"
      ],
      "metadata": {
        "id": "4G85DIJL8tCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yhat=svm_cv.predict(X_test)\n",
        "plot_confusion_matrix(Y_test,yhat)"
      ],
      "metadata": {
        "id": "YAKg78F08xeN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TASK 8\n",
        "Create a decision tree classifier object then create a GridSearchCV object tree_cv with cv = 10. Fit the object to find the best parameters from the dictionary parameters."
      ],
      "metadata": {
        "id": "iNY6N4Oq84Gt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = {'criterion': ['gini', 'entropy'],\n",
        "     'splitter': ['best', 'random'],\n",
        "     'max_depth': [2*n for n in range(1,10)],\n",
        "     'max_features': ['auto', 'sqrt'],\n",
        "     'min_samples_leaf': [1, 2, 4],\n",
        "     'min_samples_split': [2, 5, 10]}\n",
        "\n",
        "tree = DecisionTreeClassifier()"
      ],
      "metadata": {
        "id": "2cnHNhVO8_qh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tree_cv = GridSearchCV(tree,parameters,cv=10)\n",
        "tree_cv.fit(X_train, Y_train)"
      ],
      "metadata": {
        "id": "USuz3gjw9AiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"tuned hpyerparameters :(best parameters) \",tree_cv.best_params_)\n",
        "print(\"accuracy :\",tree_cv.best_score_)"
      ],
      "metadata": {
        "id": "eQUoGHjr9K3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TASK 9\n",
        "Calculate the accuracy of tree_cv on the test data using the method score:\n"
      ],
      "metadata": {
        "id": "E55iKbQE9Szv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "methods.append('Decision tree classifier')\n",
        "accuracy.append(tree_cv.score(X_test, Y_test))\n",
        "print(\"test set accuracy :\",tree_cv.score(X_test, Y_test))"
      ],
      "metadata": {
        "id": "FpordkYP9ch_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = svm_cv.predict(X_test)\n",
        "plot_confusion_matrix(Y_test,yhat)"
      ],
      "metadata": {
        "id": "lqhodIcp9gy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TASK 10\n",
        "Create a k nearest neighbors object then create a GridSearchCV object knn_cv with cv = 10. Fit the object to find the best parameters from the dictionary parameters."
      ],
      "metadata": {
        "id": "O2HQlQ8T98Tu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = {'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
        "              'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
        "              'p': [1,2]}\n",
        "\n",
        "KNN = KNeighborsClassifier()"
      ],
      "metadata": {
        "id": "8bNbi-D0-BNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn_cv = GridSearchCV(KNN,parameters,cv=10)\n",
        "knn_cv.fit(X_train, Y_train)"
      ],
      "metadata": {
        "id": "GhzRhqnN-BzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"tuned hpyerparameters :(best parameters) \",knn_cv.best_params_)\n",
        "print(\"accuracy :\",knn_cv.best_score_)"
      ],
      "metadata": {
        "id": "xZkHtYqV-HzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TASK 11\n",
        "Calculate the accuracy of tree_cv on the test data using the method score:"
      ],
      "metadata": {
        "id": "Yktti6Kr91Nz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "methods.append('K nearest neighbors')\n",
        "accuracy.append(knn_cv.score(X_test, Y_test))\n",
        "print(\"test set accuracy :\",knn_cv.score(X_test, Y_test))"
      ],
      "metadata": {
        "id": "hyA5w2mu9za_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = knn_cv.predict(X_test)\n",
        "plot_confusion_matrix(Y_test,yhat)"
      ],
      "metadata": {
        "id": "Uw6uUftP9xkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TASK 12\n",
        "Find the method performs best:"
      ],
      "metadata": {
        "id": "N8B99oRL9tDq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.barh(methods, accuracy)\n",
        "plt.xlabel('Accuracy')\n",
        "plt.ylabel('Method')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "i7QhxSHX9rSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "After comparing the accuracy of the above methods, all return the same accuracy for the test data."
      ],
      "metadata": {
        "id": "MVUFoGnv9oGK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XJFW1eca9otH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}